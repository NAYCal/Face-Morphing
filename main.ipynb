{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Morphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This program will be divided up into parts, with the final product creating a 'morph' animation of 30fps from one face to another.\n",
    "\n",
    "\"A morph is a simultaneous warp of the image shape and a cross-dissolve of the image colors. The cross-dissolve is the easy part; controlling and doing the warp is the hard part. The warp is controlled by defining a correspondence between the two pictures. The correspondence should map eyes to eyes, mouth to mouth, chin to chin, ears to ears, etc., to get the smoothest transformations possible.\n",
    "To start with, you should take a pictures of yourself on a uniform background (for instance, white). Your image should be the same size and aspect ratio as your target face (for instance, this beautiful portrait of [George](https://inst.eecs.berkeley.edu/~cs180/fa23/hw/proj3/george_small.jpg), taken by [Martin Schoeller](http://en.wikipedia.org/wiki/Martin_Schoeller)). Treat your target face as a passport photo template -- your face in the picture should be about where their face is. You can use photo editing software to resize/crop your image such that this is the case. This will make your morphing result more pleasing to the eye\". - CS 180 Fall 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Universally useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import skimage.io as skio\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as sktr\n",
    "\n",
    "from skimage import img_as_ubyte\n",
    "from scipy.spatial import Delaunay\n",
    "from skimage.draw import polygon\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for general image retrieval, storing, simple processing operations\n",
    "\n",
    "def get_file_image(fname):\n",
    "        relative_data_dir = \"data\"\n",
    "        dir = os.getcwd()\n",
    "        image_path = os.path.join(dir, relative_data_dir, fname)\n",
    "\n",
    "        image = skio.imread(image_path)\n",
    "        image = sk.img_as_float(image)\n",
    "        return image\n",
    "\n",
    "def convert_channel_to_image(r, g, b, alpha=None):\n",
    "        if alpha is None:\n",
    "                return np.dstack(([r, g, b]))\n",
    "        return img_as_ubyte(np.dstack([r, g, b, alpha]))\n",
    "\n",
    "def get_image_channels(image):\n",
    "        assert len(image.shape) == 3\n",
    "        if image.shape[2] == 3:\n",
    "                return red_channel(image), green_channel(image), blue_channel(image), None\n",
    "        elif image.shape[2] == 4:\n",
    "                return red_channel(image), green_channel(image), blue_channel(image), alpha_channel(image)\n",
    "        else:\n",
    "                raise ValueError(\"Image does not have 3 or 4 channels\")\n",
    "        \n",
    "def rgb2gray(image, with_alpha=False):\n",
    "        assert len(image.shape) == 3\n",
    "        if image.shape[2] == 3:\n",
    "                return image.dot([0.2989, 0.5870, 0.1140])\n",
    "        elif image.shape[2] == 4:\n",
    "                rgb_channels = image[:, :, :3]\n",
    "                alpha_channel = image[:, :, 3]\n",
    "                \n",
    "                grayed_rgb = rgb_channels.dot([0.2989, 0.5870, 0.1140])\n",
    "                return grayed_rgb + (1 - alpha_channel) if with_alpha else grayed_rgb\n",
    "        else:\n",
    "                raise ValueError(\"Image does not have 3 or 4 channels\")\n",
    "\n",
    "def red_channel(image):\n",
    "        return image[:, :, 0]\n",
    "\n",
    "def green_channel(image):\n",
    "        return image[:, :, 1]\n",
    "\n",
    "def blue_channel(image):\n",
    "        return image[:, :, 2]\n",
    "\n",
    "def alpha_channel(image):\n",
    "        if image.shape[2] == 4:\n",
    "                return image[:, :, 3]\n",
    "        else:\n",
    "                return None\n",
    "        \n",
    "def save_image(image, name, is_out=True):\n",
    "        # Scale image data to 0-255 range for storing\n",
    "        normalize_factor = 1\n",
    "        if image.max() <= 1.:\n",
    "                normalize_factor = 255\n",
    "        scaled_image = (image.copy() * normalize_factor).astype(np.uint8)\n",
    "        # save the image\n",
    "        file_name = 'out/' + name + '.jpg' if is_out else 'data/' + name + '.jpg'\n",
    "        skio.imsave(file_name, scaled_image)\n",
    "        \n",
    "def get_gaussian_kernel_2d(ksize, sigma):\n",
    "    k1d = cv2.getGaussianKernel(ksize=ksize, sigma=sigma)\n",
    "    k2d = k1d * k1d.T\n",
    "    return k2d\n",
    "        \n",
    "def apply_func_image(image, function):\n",
    "        if len(image.shape) == 2:\n",
    "                return function(image)\n",
    "        r, g, b, alpha = get_image_channels(image)\n",
    "        \n",
    "        r = function(r)\n",
    "        g = function(g)\n",
    "        b = function(b)\n",
    "        alpha = function(alpha) if alpha is not None else alpha\n",
    "        \n",
    "        return np.dstack([r, g, b]) if alpha is None else np.dstack([r, g, b, alpha])\n",
    "\n",
    "def apply_gaussian_blurr(image, kernel_size, kernel_sigma):\n",
    "        gaussian_kernel = get_gaussian_kernel_2d(kernel_size, kernel_sigma)\n",
    "\n",
    "def normalize(image):\n",
    "        min_val = np.min(image)\n",
    "        max_val = np.max(image)\n",
    "        normalized_image = (image - min_val) / (max_val - min_val)\n",
    "        return normalized_image\n",
    "\n",
    "def pad_image_with_white_boarders(img, top, bottom, left, right):\n",
    "    height, width = img.shape[:2]\n",
    "    num_channels = img.shape[2] if len(img.shape) > 2 else 1\n",
    "    \n",
    "    # Create white padding for each side\n",
    "    left_padding = np.ones((height, left, num_channels), dtype=img.dtype)\n",
    "    right_padding = np.ones((height, right, num_channels), dtype=img.dtype)\n",
    "    top_padding = np.ones((top, width + left + right, num_channels), dtype=img.dtype)\n",
    "    bottom_padding = np.ones((bottom, width + left + right, num_channels), dtype=img.dtype)\n",
    "    \n",
    "    # Combine original image and padding\n",
    "    img_with_left_right_padding = np.concatenate((left_padding, img, right_padding), axis=1)\n",
    "    padded_img = np.concatenate((top_padding, img_with_left_right_padding, bottom_padding), axis=0)\n",
    "\n",
    "    return padded_img\n",
    "\n",
    "def show_images(images, columns=None, figsize=(12, 13)):\n",
    "        if columns is None:\n",
    "                columns = len(images)\n",
    "        rows = math.ceil((len(images) / columns))\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, columns, figsize=figsize)\n",
    "\n",
    "        if rows == columns and columns == 1:\n",
    "                axes.imshow(images[0])                \n",
    "                return\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "                if rows == 1:\n",
    "                        axes[i].imshow(img)\n",
    "                else:\n",
    "                        row = i // columns\n",
    "                        col = i % columns\n",
    "                        axes[row][col].imshow(img)\n",
    "        \n",
    "\n",
    "def show_overlay(images, tris, columns=None, is_show_all=True, figsize=(12, 13), save_path=None):\n",
    "        assert len(images) == len(tris)\n",
    "        if columns is None:\n",
    "                columns = len(images)\n",
    "        rows = math.ceil((len(images) / columns)) + is_show_all\n",
    "        fig, axes = plt.subplots(rows, columns, figsize=figsize)\n",
    "\n",
    "        if rows == columns and columns == 1:\n",
    "                axes.imshow(images[0])\n",
    "                axes.plot(tris[0].points[:, 0], tris[0].points[:, 1], 'o', markersize=5, markeredgecolor='lime')\n",
    "                axes.triplot(tris[0].points[:, 0], tris[0].points[:, 1], tris[0].simplices, color='lightgray')\n",
    "                \n",
    "                if save_path is not None:\n",
    "                        axes.set_axis_off()\n",
    "                        axes.margins(0,0)\n",
    "                        axes.xaxis.set_major_locator(plt.NullLocator())\n",
    "                        axes.yaxis.set_major_locator(plt.NullLocator())\n",
    "                        extent = axes.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "                        plt.savefig(save_path, bbox_inches=extent, pad_inches=0)\n",
    "                return\n",
    "        \n",
    "        \n",
    "        for i, img in enumerate(img for img in images if is_show_all):\n",
    "                if rows == 1:\n",
    "                        axes[i].imshow(img)\n",
    "                else:\n",
    "                        row = i // columns\n",
    "                        col = i % columns\n",
    "                        axes[row][col].imshow(img)\n",
    "        \n",
    "        for i, (img, tri) in enumerate(zip(images, tris)):\n",
    "                index = i + is_show_all * len(images)\n",
    "                if rows == 1:\n",
    "                        axes[index].imshow(img)\n",
    "                        axes[index].plot(tri.points[:, 0], tri.points[:, 1], 'o', markersize=5, markeredgecolor='lime')\n",
    "                        axes[index].triplot(tri.points[:, 0], tri.points[:, 1], tri.simplices, color='lightgray')\n",
    "                else:\n",
    "                        row = index // columns\n",
    "                        col = index % columns\n",
    "                        axes[row][col].imshow(img)\n",
    "                        axes[row][col].plot(tri.points[:, 0], tri.points[:, 1], 'o', markersize=5, markeredgecolor='lime')\n",
    "                        axes[row][col].triplot(tri.points[:, 0], tri.points[:, 1], tri.simplices, color='lightgray')\n",
    "\n",
    "        if save_path is not None:\n",
    "                for i, ax in enumerate(axes.flatten()):\n",
    "                        ax.set_axis_off()\n",
    "                        ax.margins(0,0)\n",
    "                        ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "                        ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "                        extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "                        # You should modify save_path to have a different name for each subplot\n",
    "                        plt.savefig(f\"{save_path[:-4]}_{i}.png\", bbox_inches=extent, pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Defining Correspondences\n",
    "First, you will need to define pairs of corresponding points on the two images by hand (the more points, the better the morph, generally). The simplest way is probably to use the cpselect (matlab) tool or write your own little tool using ginput (matlab or python) and plot commands (with hold on and hold off ). In order for the morph to work you will need a consistent labeling of the two faces. So label your faces A and B in a consistent manner using the same ordering of keypoints in the two faces. It's strongly recommended that you save the points once you obtain something you are happy with so that you don't have to do all that clicking more than once!\n",
    "\n",
    "Now, you need to provide a triangulation of these points that will be used for morphing. You can compute a triangulation any way you like, or even define it by hand. A Delaunay triangulation (see delaunay and related functions) is a good choice since it does not produce overly skinny triangles. You can compute the Delaunay triangulation on either of the point sets (but not both -- the triangulation has to be the same throughout the morph!). But the best approach would probably be to compute the triangulation at a midway shape (i.e. mean of the two point sets) to lessen the potential triangle deformations.\n",
    "\n",
    "Note if you don't want to implement your own labeling tool, you can use [this one](https://inst.eecs.berkeley.edu/~cs194-26/fa22/upload/files/proj3/cs194-26-aex/tool.html) from a last year's student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triangulation_from_correspondence_file(file_name, is_display=False, is_show_all=False, save_path=None):\n",
    "    relative_data_dir = \"data\"\n",
    "    dir = os.getcwd()\n",
    "    correspondence_path = os.path.join(dir, relative_data_dir, file_name)\n",
    "    \n",
    "    with open(correspondence_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    image1 = get_file_image(data['im1_name'] + \".jpg\")\n",
    "    image2 = get_file_image(data['im2_name'] + \".jpg\")\n",
    "        \n",
    "    points1 = np.array(data['im1Points'])\n",
    "    points2 = np.array(data['im2Points'])\n",
    "    \n",
    "    # Add corner points to make wrapping easier\n",
    "    new_points = np.array([[0, 0], [image1.shape[1] - 1, 0], [0, image1.shape[0] - 1], [image1.shape[1] - 1, image1.shape[0] - 1]])\n",
    "    points1 = np.vstack((points1, new_points))\n",
    "    \n",
    "    new_points = np.array([[0, 0], [image2.shape[1] - 1, 0], [0, image2.shape[0] - 1], [image2.shape[1] - 1, image2.shape[0] - 1]])\n",
    "    points2 = np.vstack((points2, new_points))\n",
    "    \n",
    "    tri1 = Delaunay(points1)\n",
    "    tri2 = Delaunay(points2)\n",
    "    tri2.simplices = tri1.simplices.copy()  # Copy the triangle information\n",
    "    \n",
    "    if is_display:\n",
    "        show_overlay(images=[image1, image2], tris=[tri1, tri2], is_show_all=is_show_all, save_path=save_path)\n",
    "    return image1, image2, tri1, tri2\n",
    "\n",
    "tofu_img, crisp_img, tofu_tri, crisp_tri = get_triangulation_from_correspondence_file('tofu_with_chains_crisp.json', True, True, save_path='out/overlay_images/tofu_crisp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, dominic_fike_img, me_tri, dominic_fike_tri = get_triangulation_from_correspondence_file('me_dominic_fike.json', True, True, save_path='out/overlay_images/me_dominic_fike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, kaiona_img, me_tri, kaiona_tri = get_triangulation_from_correspondence_file('me_kaiona.json', True, True, save_path='out/overlay_images/me_kaiona')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Computing the \"Mid-way Face\"\n",
    "\n",
    "In this part, we will compute the \"Mid-way Face\" between the first image to the final image. First, we will find the transitional image between the first and final image by taking a weighted average. Then, we will find the affine transformation matrix from both images to the transitional image. Finally, we will use the new found affine transformation matrix to perform wrapping and color dissolution.\n",
    "\n",
    "\n",
    "To find the affine transformation function, we can use the corresponding points taken during Part 1 to solve for the affine transformation matrix. Since there are 6 unknowns, we will need 3 points (Note: Each point has an x and y component). After finding the affine transformation matrix, we can use inverse wrapping to take pixels from our first image into our new \"Mid-way Face\" image.\n",
    "\n",
    "Affine Transformation with Homogenous coordinates:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "   x' \\\\\n",
    "   y' \\\\\n",
    "   1 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "   a & b & c \\\\\n",
    "   d & e & f \\\\\n",
    "   0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "   x \\\\\n",
    "   y \\\\\n",
    "   1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Solving for Affine Transformation through Correspondence points:\n",
    "<div style=\"text-align: center;\">\n",
    "\n",
    "In linear algebra:\n",
    "\n",
    "x<sub>1</sub>' = ax<sub>1</sub> + by<sub>1</sub> + c \\\n",
    "x<sub>2</sub>' = ax<sub>2</sub> + by<sub>2</sub> + c \\\n",
    "x<sub>3</sub>' = ax<sub>3</sub> + by<sub>3</sub> + c\n",
    "\n",
    "y<sub>1</sub>' = dx<sub>1</sub> + ey<sub>1</sub> + f \\\n",
    "y<sub>2</sub>' = dx<sub>2</sub> + ey<sub>2</sub> + f \\\n",
    "y<sub>3</sub>' = dx<sub>3</sub> + ey<sub>3</sub> + f \n",
    "\n",
    "Using matrix calculations:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "   a & b & c \\\\\n",
    "   d & e & f \\\\\n",
    "   0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "   x_{1} & x_{2} & x_{3} \\\\\n",
    "   y_{1} & y_{2} & y_{3} \\\\\n",
    "   1 & 1 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "   x_{1}' & x_{2}' & x_{3}' \\\\\n",
    "   y_{1}' & y_{2}' & y_{3}' \\\\\n",
    "   1 & 1 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "   a & b & c \\\\\n",
    "   d & e & f \\\\\n",
    "   0 & 0 & 1 \\\\ \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "   x_{1}' & x_{2}' & x_{3}' \\\\\n",
    "   y_{1}' & y_{2}' & y_{3}' \\\\\n",
    "   1 & 1 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "   x_{1} & x_{2} & x_{3} \\\\\n",
    "   y_{1} & y_{2} & y_{3} \\\\\n",
    "   1 & 1 & 1 \\\\\n",
    "\\end{bmatrix}^{-1}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: left;\">\n",
    "Note: Unlike conventional matrix calculations, the image representations in python are (y, x) where y represents the vertical value and x represents the horrizontal value. However, this does not affect our calculations since the rows in the affine matrix is correspondingly flipped as well!\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "   a & b & c \\\\\n",
    "   d & e & f \\\\\n",
    "   0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "   y_{1} & y_{2} & y_{3} \\\\\n",
    "   x_{1} & x_{2} & x_{3} \\\\\n",
    "   1 & 1 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "   y_{1}' & y_{2}' & y_{3}' \\\\\n",
    "   x_{1}' & x_{2}' & x_{3}' \\\\\n",
    "   1 & 1 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "   a & b & c \\\\\n",
    "   d & e & f \\\\\n",
    "   0 & 0 & 1 \\\\ \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "   y_{1}' & y_{2}' & y_{3}' \\\\\n",
    "   x_{1}' & x_{2}' & x_{3}' \\\\\n",
    "   1 & 1 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "   y_{1} & y_{2} & y_{3} \\\\\n",
    "   x_{1} & x_{2} & x_{3} \\\\\n",
    "   1 & 1 & 1 \\\\\n",
    "\\end{bmatrix}^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_affine_function(src_pts, dest_pts):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        src_pts (_type_): _description_\n",
    "        dest_pts (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    assert type(src_pts) == type(dest_pts)\n",
    "    \n",
    "    if not isinstance(src_pts, np.ndarray):\n",
    "        assert len(src_pts) >= 3 and len(dest_pts) == len(src_pts)\n",
    "        assert len(src_pts[0]) == 2 and len(dest_pts[0]) == 2\n",
    "        \n",
    "        src_pts = np.array(src_pts)\n",
    "        dest_pts = np.array(dest_pts)\n",
    "        \n",
    "    assert src_pts.shape == dest_pts.shape\n",
    "    ones_row = np.ones((1, src_pts.shape[0]))\n",
    "    \n",
    "    src_pts = np.vstack((src_pts.T, ones_row))\n",
    "    dest_pts = np.vstack((dest_pts.T, ones_row))\n",
    "    src_pts_inverse = np.linalg.inv(src_pts)\n",
    "    \n",
    "    return np.dot(dest_pts, src_pts_inverse)\n",
    "\n",
    "def get_shape_size(pts):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        pts (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    max_y = np.max(pts[:, 1])\n",
    "    max_x = np.max(pts[:, 0])\n",
    "    \n",
    "    height = math.ceil(max_y) + 1\n",
    "    width = math.ceil(max_x) + 1\n",
    "\n",
    "    return height, width\n",
    "\n",
    "def get_triangle_coords(triangle_vertices):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        triangle_vertices (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return polygon(triangle_vertices[:, 1], triangle_vertices[:, 0])\n",
    "    \n",
    "\n",
    "def get_transition_img(img_shape, src_tri, dest_tri, wrap_frac=0.5):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        src_tri (_type_): _description_\n",
    "        dest_tri (_type_): _description_\n",
    "        wrap_frac (float, optional): _description_. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    transition_tri = Delaunay((1-wrap_frac) * src_tri.points + wrap_frac * dest_tri.points)\n",
    "    transition_tri.simplices = src_tri.simplices.copy()\n",
    "    transition_image = np.zeros(img_shape)\n",
    "    \n",
    "    return transition_image, transition_tri\n",
    "\n",
    "def inverse_warping(src_img, dest_img, result_im, src_pts, dest_pts, transition_pts, dissolve_frac=0.5): \n",
    "    \"\"\"Performs inverse wrapping within the triangle points.\n",
    "\n",
    "    Args:\n",
    "        src_img (_type_): The image that we want to morph from\n",
    "        dest_img (_type_): The final image that we want to morph into\n",
    "        result_im (_type_): The current image that we are morphing into\n",
    "        src_pts (_type_): The points in the beginning image\n",
    "        dest_pts (_type_): The points in the final image\n",
    "        transition_pts (_type_): The points we are currently morphing into\n",
    "        dissolve_frac (float, optional): The degree of color dissolution we want. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    src_affine_matrix = compute_affine_function(transition_pts, src_pts)\n",
    "    dest_affine_matrix = compute_affine_function(transition_pts, dest_pts)\n",
    "    \n",
    "    transition_y, transition_x = get_triangle_coords(transition_pts)\n",
    "    homogenous_transition_coords = np.vstack([transition_x, transition_y, np.ones_like(transition_y)])\n",
    "    homogenous_src_coords = np.dot(src_affine_matrix, homogenous_transition_coords)\n",
    "    homogenous_dest_coords = np.dot(dest_affine_matrix, homogenous_transition_coords)\n",
    "    \n",
    "    src_x, src_y = homogenous_src_coords[0, :], homogenous_src_coords[1, :]\n",
    "    dest_x, dest_y = homogenous_dest_coords[0, :], homogenous_dest_coords[1, :]\n",
    "    \n",
    "    src_x, src_y = np.round(src_x).astype(int), np.round(src_y).astype(int)\n",
    "    dest_x, dest_y = np.round(dest_x).astype(int), np.round(dest_y).astype(int)\n",
    "    \n",
    "    in_bounds_indexes = (\n",
    "        (0 <= src_x) & (src_x < src_img.shape[1]) &\n",
    "        (0 <= src_y) & (src_y < src_img.shape[0]) &\n",
    "        (0 <= dest_x) & (dest_x < dest_img.shape[1]) &\n",
    "        (0 <= dest_y) & (dest_y < dest_img.shape[0]) &\n",
    "        (0 <= transition_y) & (transition_y < result_im.shape[0]) &\n",
    "        (0 <= transition_x) & (transition_x < result_im.shape[1])\n",
    "    )\n",
    "    \n",
    "    transition_y, transition_x = transition_y[in_bounds_indexes], transition_x[in_bounds_indexes]\n",
    "    src_x, src_y = src_x[in_bounds_indexes], src_y[in_bounds_indexes]\n",
    "    dest_x, dest_y = dest_x[in_bounds_indexes], dest_y[in_bounds_indexes]\n",
    "    \n",
    "    result_im[transition_y, transition_x, :] = (\n",
    "        (1 - dissolve_frac) * src_img[src_y, src_x, :] + \n",
    "        dissolve_frac * dest_img[dest_y, dest_x, :]\n",
    "    )\n",
    "    \n",
    "    return result_im\n",
    "\n",
    "def morph(src_img, dest_img, src_tri, dest_tri, transition_im=None, transition_tri=None, wrap_frac=0.5, dissolve_frac=0.5):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        src_img (_type_): _description_\n",
    "        dest_img (_type_): _description_\n",
    "        src_tri (_type_): _description_\n",
    "        dest_tri (_type_): _description_\n",
    "        transition_im (_type_, optional): _description_. Defaults to None.\n",
    "        transition_tri (_type_, optional): _description_. Defaults to None.\n",
    "        wrap_frac (float, optional): _description_. Defaults to 0.5.\n",
    "        dissolve_frac (float, optional): _description_. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    if transition_im is None:\n",
    "        transition_im, transition_tri = get_transition_img(src_img.shape, src_tri, dest_tri, wrap_frac)\n",
    "    \n",
    "    for simplex in src_tri.simplices:\n",
    "        src_pts = src_tri.points[simplex]\n",
    "        dest_pts = dest_tri.points[simplex]\n",
    "        transition_pts = transition_tri.points[simplex]\n",
    "        \n",
    "        transition_im = inverse_warping(src_img, dest_img, transition_im, src_pts, dest_pts, transition_pts, dissolve_frac)\n",
    "    \n",
    "    normalized_transition_im = np.clip(normalize(transition_im), 0, 1)\n",
    "    \n",
    "    return normalized_transition_im, transition_tri    \n",
    "        \n",
    "# Show results\n",
    "tofu_img, crisp_img, tofu_tri, crisp_tri = get_triangulation_from_correspondence_file('tofu_with_chains_crisp.json', False)\n",
    "tofu_crisp_transition_image, tofu_crisp_transition_tri = morph(tofu_img, crisp_img, tofu_tri, crisp_tri)\n",
    "\n",
    "images = [tofu_img, tofu_crisp_transition_image, crisp_img]\n",
    "tris = [tofu_tri, tofu_crisp_transition_tri, crisp_tri]\n",
    "\n",
    "os.makedirs('out/overlay_images/tofu_crisp_transition', exist_ok=True)\n",
    "show_overlay(images, tris, columns=3, is_show_all=True, save_path='out/overlay_images/tofu_crisp_transition')\n",
    "# show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, dominic_fike_img, me_tri, dominic_fike_tri = get_triangulation_from_correspondence_file('me_dominic_fike.json', False)\n",
    "me_dominic_fike_transition_image, me_dominic_fike_transition_tri = morph(me_img, dominic_fike_img, me_tri, dominic_fike_tri)\n",
    "\n",
    "images = [me_img, me_dominic_fike_transition_image, dominic_fike_img]\n",
    "tris = [me_tri, me_dominic_fike_transition_tri, dominic_fike_tri]\n",
    "\n",
    "os.makedirs('out/overlay_images/me_dominic_transition', exist_ok=True)\n",
    "show_overlay(images, tris, columns=3, is_show_all=True, save_path='out/overlay_images/me_dominic_transition')\n",
    "# show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "save_image(me_dominic_fike_transition_image, \"me_dominic_fike_combine_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, kaiona_img, me_tri, kaiona_tri = get_triangulation_from_correspondence_file('me_kaiona.json', False)\n",
    "me_kaiona_transition_image, me_kaiona_transition_tri = morph(me_img, kaiona_img, me_tri, kaiona_tri)\n",
    "\n",
    "images = [me_img, me_kaiona_transition_image, kaiona_img]\n",
    "tris = [me_tri, me_kaiona_transition_tri, dominic_fike_tri]\n",
    "\n",
    "os.makedirs('out/overlay_images/me_kaiona_transition', exist_ok=True)\n",
    "show_overlay(images, tris, columns=3, is_show_all=True, save_path='out/overlay_images/me_kaiona_transition')\n",
    "# show_overlay(images, tris, columns=3, is_show_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 The Morph Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif_from_images(image_list, gif_name='animated.gif', duration=None):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        image_list (_type_): _description_\n",
    "        gif_name (str, optional): _description_. Defaults to 'animated.gif'.\n",
    "    \"\"\"\n",
    "    os.makedirs('out/gif_folder', exist_ok=True)\n",
    "    os.makedirs('out/image_folder', exist_ok=True)\n",
    "    pil_images = []\n",
    "    \n",
    "    if duration is None:\n",
    "        duration = len(image_list) // 30\n",
    "    \n",
    "    for i, img in enumerate(image_list):\n",
    "        if img.dtype == np.float32 or img.dtype == np.float64:\n",
    "            img = (img * 255).astype('uint8')\n",
    "        \n",
    "        img_name = gif_name[:-4]\n",
    "        img_path = os.path.join('out/image_folder', f'{img_name}_{i}.jpg')\n",
    "        \n",
    "        # Save the image with skimage.io\n",
    "        skio.imsave(img_path, img)\n",
    "        \n",
    "        img_pil = Image.open(img_path)\n",
    "        pil_images.append(img_pil)\n",
    "\n",
    "    # Save images as a GIF\n",
    "    gif_path = os.path.join('out/gif_folder', gif_name)\n",
    "    pil_images[0].save(gif_path, save_all=True, append_images=pil_images[1:], loop=0, duration=duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_morph_sequence_from_file(file_name, num_sequence=45, is_save_images=True):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        file_name (_type_): _description_\n",
    "        num_sequence (int, optional): _description_. Defaults to 45.\n",
    "        is_save_images (bool, optional): _description_. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    assert num_sequence > 0\n",
    "    src_img, dest_img, src_tri, dest_tri = get_triangulation_from_correspondence_file(file_name)\n",
    "    wrap_frac=0\n",
    "    dissolve_frac=0\n",
    "    \n",
    "    frac_growth_rate = 1 / num_sequence\n",
    "    \n",
    "    morph_sequence = [src_img]\n",
    "    morph_tris = [src_tri]\n",
    "    \n",
    "    for i in range(num_sequence):\n",
    "        wrap_frac += float(frac_growth_rate)\n",
    "        dissolve_frac += float(frac_growth_rate)\n",
    "        transitional_im, transitional_tri = morph(src_img, dest_img, src_tri, dest_tri, wrap_frac=wrap_frac, dissolve_frac=wrap_frac)\n",
    "        \n",
    "        morph_sequence.append(transitional_im)\n",
    "        morph_tris.append(transitional_tri)\n",
    "    \n",
    "        \n",
    "    morph_sequence.append(dest_img)\n",
    "    morph_tris.append(dest_tri)\n",
    "    if is_save_images:\n",
    "        print(\"Saving images. Do not turn off power.\")\n",
    "        create_gif_from_images(morph_sequence, file_name[:-5]+'.gif')\n",
    "        print(\"Images saved.\")\n",
    "    return morph_sequence, morph_tris\n",
    "\n",
    "# Uncomment to get the gifs\n",
    "get_morph_sequence_from_file('tofu_with_chains_crisp.json')\n",
    "get_morph_sequence_from_file('me_dominic_fike.json')\n",
    "get_morph_sequence_from_file('me_kaiona.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. The \"Mean face\" of a population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to help store the points and image from danes dataset. Allows better readability\n",
    "# Goal: Have one class that stores the image and their corresponding data points\n",
    "# Note: Since the image file name is already stored in the asf file, we only need to pass in the asf file.\n",
    "#       To ensure that the background is also added when morphing, I manually harded the corners into points\n",
    "def read_asf_file(fname):\n",
    "    if fname[-4:] != '.asf':\n",
    "        fname += '.asf'\n",
    "    relative_data_dir = \"data/danes/\"\n",
    "    dir = os.getcwd()\n",
    "    file_path = os.path.join(dir, relative_data_dir, fname)\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "class DanesDataset:\n",
    "    def __init__(self):\n",
    "        self.danes_images = {}\n",
    "        self.get_data()\n",
    "        \n",
    "    def get_data(self):\n",
    "        file_pattern = '*.asf' \n",
    "        full_pattern = \"data/danes/\" + file_pattern\n",
    "        file_list = glob.glob(full_pattern)  \n",
    "\n",
    "        for file_path in file_list:\n",
    "            fname = os.path.basename(file_path)\n",
    "            self.danes_images[int(fname[:2])] = self.DanesImage(fname)\n",
    "            \n",
    "    def get_image(self, im_num):\n",
    "        return self.danes_images[im_num].im\n",
    "    \n",
    "    def show_overlay(self, im_num):\n",
    "        self.danes_images[im_num].show_overlay()\n",
    "    \n",
    "    def get_im_pts_tri(self, im_num):\n",
    "        dan_im = self.danes_images[im_num]\n",
    "        return dan_im.im, dan_im.get_coords(), dan_im.get_tri()\n",
    "    \n",
    "    def get_all_im_pts_tri(self):\n",
    "        img_list = []\n",
    "        pts = []\n",
    "        tris = []\n",
    "        \n",
    "        for index in self.danes_images.keys():\n",
    "            img, pt, tri = self.get_im_pts_tri(index)\n",
    "            img_list.append(img)\n",
    "            pts.append(pt)\n",
    "            tris.append(tri)\n",
    "            \n",
    "        # make sure all the tris get the same triangles to avoid folding\n",
    "        for i in range(len(tris)):\n",
    "            tris[i].simplices = tris[0].simplices.copy()\n",
    "            \n",
    "        return img_list, pts, tris\n",
    "\n",
    "    \n",
    "    class DanesImage:\n",
    "        def __init__(self, fname):\n",
    "            self.im = None\n",
    "            self.data_pts = {}\n",
    "            self.parse_danes_asf_file(fname)\n",
    "        \n",
    "        def parse_danes_asf_file(self, fname):\n",
    "            lines = read_asf_file(fname)            \n",
    "            points_pattern = re.compile(r'(\\d+)\\s+(\\d+)\\s+(-?\\d+\\.\\d+)\\s+(-?\\d+\\.\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)')\n",
    "            \n",
    "            # format: <path#> <type> <x rel.> <y rel.> <point#> <connects from> <connects to>\n",
    "            for pt in points_pattern.findall(lines):\n",
    "                assert len(pt) == 7\n",
    "                self.data_pts[int(pt[4])] = self.Datapoint(*pt)\n",
    "            image_fname_pattern = re.compile(r'.+\\.bmp')\n",
    "            im_fname = image_fname_pattern.search(lines).group()\n",
    "            self.im = get_file_image(\"Danes/\"+im_fname)\n",
    "            \n",
    "            # Manually added corners as points to help with wrapping.\n",
    "            \n",
    "            self.data_pts[-1] = self.Datapoint(\"-1\", \"-1\", \"0\", \"0\", \"-1\", \"-1\", \"-1\")\n",
    "            self.data_pts[-2] = self.Datapoint(\"-2\", \"-1\", \"0\", \"1\", \"-2\", \"-2\", \"-2\")\n",
    "            self.data_pts[-3] = self.Datapoint(\"-3\", \"-1\", \"1\", \"0\", \"-3\", \"-3\", \"-3\")\n",
    "            self.data_pts[-4] = self.Datapoint(\"-4\", \"-1\", \"1\", \"1\", \"-4\", \"-4\", \"-4\")\n",
    "            \n",
    "        \n",
    "        def get_coord(self, pt_num):\n",
    "            return self.data_pts[pt_num].get_coord(self.im)\n",
    "        \n",
    "        def get_coords(self):\n",
    "            coords = []\n",
    "            \n",
    "            for pt in self.data_pts.values():\n",
    "                x, y = pt.get_rel_coord()\n",
    "                coords.append([x, y])\n",
    "            \n",
    "            coords = np.array(coords)\n",
    "            coords[:, 0] *= self.im.shape[1]\n",
    "            coords[:, 1] *= self.im.shape[0]\n",
    "            return coords\n",
    "        \n",
    "        def get_tri(self):\n",
    "            pts = self.get_coords()\n",
    "            return Delaunay(pts)\n",
    "        \n",
    "        def show_overlay(self):\n",
    "            pts = self.get_coords()\n",
    "            tri = self.get_tri()\n",
    "            fig, axes = plt.subplots(1, 1, figsize=(10, 10))\n",
    "            axes.imshow(self.im)\n",
    "            axes.plot(pts[:, 0], pts[:, 1], 'o', markersize=5, markeredgecolor='lime')\n",
    "            axes.triplot(tri.points[:, 0], tri.points[:, 1], tri.simplices, color='lightgray')\n",
    "            \n",
    "        \n",
    "        class Datapoint:\n",
    "            def __init__(self, path_num, pt_type, relative_x, relative_y, point_num, connect_from, connect_to):\n",
    "                self.path_num =int(path_num)\n",
    "                self.type = int(pt_type)\n",
    "                self.relative_x = float(relative_x)\n",
    "                self.relative_y = float(relative_y)\n",
    "                self.point_num = int(point_num) # Unique ID of point, store here for debugging for now\n",
    "                self.connect_from = int(connect_from)\n",
    "                self.connect_to = int(connect_to)\n",
    "            \n",
    "            def get_coord(self, im):\n",
    "                x = round(self.relative_x * im.shape[1])\n",
    "                y = round(self.relative_y * im.shape[0])\n",
    "                \n",
    "                return x, y\n",
    "            \n",
    "            def get_rel_coord(self):\n",
    "                return self.relative_x, self.relative_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_transition_im(im_shape, src_pts_list, src_tri_list):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        src_pts_list (_type_): _description_\n",
    "        src_tri_list (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    avg_pts = np.round(np.mean(np.array(src_pts_list), axis = 0))\n",
    "    avg_tri = Delaunay(avg_pts)\n",
    "    avg_tri.simplices = src_tri_list[0].simplices.copy()\n",
    "    \n",
    "    avg_image = np.zeros(im_shape)\n",
    "    \n",
    "    # avg_image = np.zeros((*get_shape_size(avg_pts), 3))\n",
    "    \n",
    "    return avg_image, avg_tri\n",
    "\n",
    "def compute_inverse_coords(src_pts, result_pts):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        src_pts (_type_): _description_\n",
    "        result_pts (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    result_y_in_tri, result_x_in_tri = get_triangle_coords(result_pts)\n",
    "    homogenous_result_coords = np.vstack([result_x_in_tri, result_y_in_tri, np.ones_like(result_y_in_tri)])\n",
    "    \n",
    "    affine_matrix = compute_affine_function(src_pts, result_pts)\n",
    "    affine_matrix = np.linalg.inv(affine_matrix)\n",
    "    \n",
    "    homogenous_img_coords = np.dot(affine_matrix, homogenous_result_coords)\n",
    "    img_x, img_y = homogenous_img_coords[0, :], homogenous_img_coords[1, :]\n",
    "\n",
    "    return img_y, img_x, result_y_in_tri, result_x_in_tri\n",
    "\n",
    "def bilinear_interpolation(image, y, x):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        image (_type_): _description_\n",
    "        y (_type_): _description_\n",
    "        x (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    y_floor = np.floor(y).astype(int)\n",
    "    x_floor = np.floor(x).astype(int)\n",
    "    \n",
    "    in_bounds_indexes = (\n",
    "        (0 <= x_floor) & (x_floor + 1 < image.shape[1]) &\n",
    "        (0 <= y_floor) & (y_floor + 1 < image.shape[0])\n",
    "    )\n",
    "    \n",
    "    y_floor = y_floor[in_bounds_indexes]\n",
    "    x_floor = x_floor[in_bounds_indexes]\n",
    "    \n",
    "    # Also filter y and x with the in_bounds_indexes\n",
    "    y = y[in_bounds_indexes]\n",
    "    x = x[in_bounds_indexes]\n",
    "    \n",
    "    \n",
    "    value_top_left = image[y_floor, x_floor, :]\n",
    "    value_top_right = image[y_floor, x_floor + 1, :]\n",
    "    value_bottom_left = image[y_floor + 1, x_floor, :]\n",
    "    value_bottom_right = image[y_floor + 1, x_floor + 1, :]\n",
    "    \n",
    "    # For weight calculation\n",
    "    x_relative = (x - x_floor).reshape(-1, 1)\n",
    "    y_relative = (y - y_floor).reshape(-1, 1)\n",
    "    \n",
    "    top_left_weight = (1 - x_relative) * (1 - y_relative)\n",
    "    top_right_weight = (1 - x_relative) * y_relative\n",
    "    bottom_left_weight = x_relative * (1 - y_relative)\n",
    "    bottom_right_weight =  x_relative * y_relative\n",
    "    \n",
    "    value_top_left = top_left_weight * value_top_left\n",
    "    value_top_right = top_right_weight * value_top_right\n",
    "    value_bottom_left = bottom_left_weight * value_bottom_left\n",
    "    value_bottom_right = bottom_right_weight * value_bottom_right\n",
    "    \n",
    "    return value_top_left + value_top_right + value_bottom_left + value_bottom_right, in_bounds_indexes\n",
    "\n",
    "def nearest_neighbor(image, y, x):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        image (_type_): _description_\n",
    "        y (_type_): _description_\n",
    "        x (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    img_y, img_x = np.round(y).astype(int), np.round(x).astype(int)\n",
    "    in_bounds_indexes = (\n",
    "        (0 <= img_x) & (img_x < image.shape[1]) &\n",
    "        (0 <= img_y) & (img_y < image.shape[0]) \n",
    "    )\n",
    "    img_y, img_x = img_y[in_bounds_indexes], img_x[in_bounds_indexes]\n",
    "    \n",
    "    return image[img_y, img_x, :], in_bounds_indexes\n",
    "    \n",
    "\n",
    "def running_average_inverse_wrapping(img, result_im, tris, result_tris, running_count=0):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        img (_type_): _description_\n",
    "        result_im (_type_): _description_\n",
    "        tris (_type_): _description_\n",
    "        result_tris (_type_): _description_\n",
    "        running_count (int, optional): _description_. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    average_frac = 1 / (running_count + 1)\n",
    "    \n",
    "    temp_result_im = np.zeros_like(result_im)\n",
    "    count_matrix = np.zeros_like(result_im, dtype=int)\n",
    "    for simplex in tris.simplices:\n",
    "        pts = tris.points[simplex]\n",
    "        result_pts = result_tris.points[simplex]\n",
    "\n",
    "        img_y, img_x, result_y_in_tri, result_x_in_tri = compute_inverse_coords(pts, result_pts)\n",
    "        \n",
    "        interpolated_value, in_bounds_indexes = bilinear_interpolation(img, img_y, img_x)\n",
    "        result_y_in_tri, result_x_in_tri = result_y_in_tri[in_bounds_indexes], result_x_in_tri[in_bounds_indexes]\n",
    "        temp_result_im[result_y_in_tri, result_x_in_tri, :] += interpolated_value\n",
    "        \n",
    "        count_matrix[result_y_in_tri, result_x_in_tri, :] += 1\n",
    "        \n",
    "    overlapping_areas = count_matrix > 1\n",
    "    temp_result_im[overlapping_areas] /= count_matrix[overlapping_areas]\n",
    "    result_im = (1 - average_frac) * result_im + average_frac * temp_result_im\n",
    "    \n",
    "    return result_im\n",
    "        \n",
    "\n",
    "def average_morph(img_list, img_pts_list, img_tris_list):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        img_list (_type_): _description_\n",
    "        img_pts_list (_type_): _description_\n",
    "        img_tris_list (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    avg_im, avg_tri = get_average_transition_im(img_list[0].shape, img_pts_list, img_tris_list)\n",
    "        \n",
    "    for i, (img, tri) in enumerate(zip(img_list, img_tris_list)):\n",
    "        avg_im = running_average_inverse_wrapping(img, avg_im, tri, avg_tri, i)\n",
    "        \n",
    "    # avg_im = normalize(avg_im / len(img_list))\n",
    "    return normalize(avg_im), avg_tri\n",
    "\n",
    "\n",
    "danes_im_list, danes_pts_list, danes_tris_list = DanesDataset().get_all_im_pts_tri()\n",
    "avg_danes_im, avg_danes_tri = average_morph(danes_im_list, danes_pts_list, danes_tris_list)\n",
    "skio.imshow(avg_danes_im)\n",
    "skio.show()\n",
    "save_image(avg_danes_im, \"average_face_in_danes_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danes_morph_to_average_image = []\n",
    "danes_morph_to_average_tris = []\n",
    "danes_im_list, danes_pts_list, danes_tris_list = DanesDataset().get_all_im_pts_tri()\n",
    "avg_danes_im, avg_danes_tri = average_morph(danes_im_list, danes_pts_list, danes_tris_list)\n",
    "\n",
    "os.makedirs('out/morphed_danes_to_average', exist_ok=True)\n",
    "for i, (img, pts, tris) in enumerate(zip(danes_im_list, danes_pts_list, danes_tris_list)):\n",
    "    morphed_im, morphed_tris = morph(img, avg_danes_im, tris, avg_danes_tri, wrap_frac=0.5, dissolve_frac=0.5)\n",
    "    danes_morph_to_average_image.append(morphed_im)\n",
    "    danes_morph_to_average_tris.append(morphed_tris)\n",
    "    \n",
    "    save_image(morphed_im, \"morphed_danes_to_average/image{}\".format(i))  \n",
    "    \n",
    "show_images(danes_morph_to_average_image, columns=8, figsize=(22, 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danes_wrapped_to_average_image = []\n",
    "danes_wrapped_to_average_tris = []\n",
    "danes_im_list, danes_pts_list, danes_tris_list = DanesDataset().get_all_im_pts_tri()\n",
    "avg_danes_im, avg_danes_tri = average_morph(danes_im_list, danes_pts_list, danes_tris_list)\n",
    "\n",
    "os.makedirs('out/wrapped_danes_to_average', exist_ok=True)\n",
    "for i, (img, pts, tris) in enumerate(zip(danes_im_list, danes_pts_list, danes_tris_list)):\n",
    "    wrapped_im, wrapped_tris = morph(img, avg_danes_im, tris, avg_danes_tri, wrap_frac=1, dissolve_frac=0)\n",
    "    danes_wrapped_to_average_image.append(wrapped_im)\n",
    "    danes_wrapped_to_average_tris.append(wrapped_tris)\n",
    "    \n",
    "    save_image(wrapped_im, \"wrapped_danes_to_average/image{}\".format(i))  \n",
    "    \n",
    "show_images(danes_wrapped_to_average_image, columns=8, figsize=(22, 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri = get_triangulation_from_correspondence_file('me_average_face_in_danes_dataset_for_morphing_white_background.json')\n",
    "morphed_me_avg_dane_im, morphed_me_avg_dane_tri = morph(me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri, wrap_frac=0.5, dissolve_frac=0.5)\n",
    "show_overlay([me_img, morphed_me_avg_dane_im, average_face_in_danes_img], [me_tri, morphed_me_avg_dane_tri, average_face_in_danes_tri], columns=3, is_show_all=True)\n",
    "save_image(morphed_me_avg_dane_im, 'me_average_face_in_danes_dataset_for_morphing_white_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri = get_triangulation_from_correspondence_file('me_average_face_in_danes_dataset_for_morphing_white_background.json')\n",
    "morphed_me_avg_dane_im, morphed_me_avg_dane_tri = morph(me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri, wrap_frac=0, dissolve_frac=0.5)\n",
    "show_overlay([me_img, morphed_me_avg_dane_im, average_face_in_danes_img], [me_tri, morphed_me_avg_dane_tri, average_face_in_danes_tri], columns=3, is_show_all=True)\n",
    "save_image(morphed_me_avg_dane_im, 'me_average_danes_color_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri = get_triangulation_from_correspondence_file('me_average_face_in_danes_dataset_for_morphing_white_background.json')\n",
    "morphed_me_avg_dane_im, morphed_me_avg_dane_tri = morph(me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri, wrap_frac=0.5, dissolve_frac=0)\n",
    "show_overlay([me_img, morphed_me_avg_dane_im, average_face_in_danes_img], [me_tri, morphed_me_avg_dane_tri, average_face_in_danes_tri], columns=3, is_show_all=True)\n",
    "save_image(morphed_me_avg_dane_im, 'me_average_danes_wrapping_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_morph_sequence_from_file('me_average_face_in_danes_dataset_for_morphing_white_background.json', num_sequence=45, is_save_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Caricatures: Extrapolating from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri = get_triangulation_from_correspondence_file('me_average_face_in_danes_dataset_for_morphing_white_background.json')\n",
    "morphed_me_avg_dane_im, morphed_me_avg_dane_tri = morph(me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri, wrap_frac=-0.2, dissolve_frac=0)\n",
    "show_overlay([me_img, morphed_me_avg_dane_im, average_face_in_danes_img], [me_tri, morphed_me_avg_dane_tri, average_face_in_danes_tri], columns=3, is_show_all=True)\n",
    "save_image(morphed_me_avg_dane_im, 'me_extrapolated_average_face_in_danes_alpha_0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri = get_triangulation_from_correspondence_file('me_average_face_in_danes_dataset_for_morphing_white_background.json')\n",
    "morphed_me_avg_dane_im, morphed_me_avg_dane_tri = morph(me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri, wrap_frac=-0.4, dissolve_frac=0)\n",
    "show_overlay([me_img, morphed_me_avg_dane_im, average_face_in_danes_img], [me_tri, morphed_me_avg_dane_tri, average_face_in_danes_tri], columns=3, is_show_all=True)\n",
    "save_image(morphed_me_avg_dane_im, 'me_extrapolated_average_face_in_danes_alpha_0.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri = get_triangulation_from_correspondence_file('me_average_face_in_danes_dataset_for_morphing_white_background.json')\n",
    "morphed_me_avg_dane_im, morphed_me_avg_dane_tri = morph(me_img, average_face_in_danes_img, me_tri, average_face_in_danes_tri, wrap_frac=-0.6, dissolve_frac=0)\n",
    "show_overlay([me_img, morphed_me_avg_dane_im, average_face_in_danes_img], [me_tri, morphed_me_avg_dane_tri, average_face_in_danes_tri], columns=3, is_show_all=True)\n",
    "save_image(morphed_me_avg_dane_im, 'me_extrapolated_average_face_in_danes_alpha_0.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danes_im_list, danes_pts_list, danes_tris_list = DanesDataset().get_all_im_pts_tri()\n",
    "avg_danes_im, avg_danes_tri = average_morph(danes_im_list, danes_pts_list, danes_tris_list)\n",
    "morphed_first_danes__avg_dane_im_alpha_point_2, morphed_first_danes_avg_dane_tri_2 = morph(\n",
    "    danes_im_list[0], \n",
    "    average_face_in_danes_img, \n",
    "    danes_tris_list[0], avg_danes_tri,\n",
    "    wrap_frac=-0.6, dissolve_frac=0\n",
    ")\n",
    "morphed_first_danes__avg_dane_im_alpha_point_4, morphed_first_danes_avg_dane_tri_4 = morph(\n",
    "    danes_im_list[0], \n",
    "    average_face_in_danes_img,  \n",
    "    danes_tris_list[0], avg_danes_tri,\n",
    "    wrap_frac=-1.2, dissolve_frac=0\n",
    ")\n",
    "morphed_first_danes__avg_dane_im_alpha_point_6, morphed_first_danes_avg_dane_tri_6 = morph(\n",
    "    danes_im_list[0], \n",
    "    average_face_in_danes_img,  \n",
    "    danes_tris_list[0], avg_danes_tri,\n",
    "    wrap_frac=-1.8, dissolve_frac=0\n",
    ")\n",
    "\n",
    "show_overlay(\n",
    "    [morphed_first_danes__avg_dane_im_alpha_point_2, morphed_first_danes__avg_dane_im_alpha_point_4, morphed_first_danes__avg_dane_im_alpha_point_6], \n",
    "    [morphed_first_danes_avg_dane_tri_2, morphed_first_danes_avg_dane_tri_4, morphed_first_danes_avg_dane_tri_6], \n",
    "    columns=3, is_show_all=True\n",
    ")\n",
    "save_image(morphed_first_danes__avg_dane_im_alpha_point_2, 'morphed_first_danes__avg_dane_im_alpha_point_0.6')\n",
    "save_image(morphed_first_danes__avg_dane_im_alpha_point_4, 'morphed_first_danes__avg_dane_im_alpha_point_1.2')\n",
    "save_image(morphed_first_danes__avg_dane_im_alpha_point_6, 'morphed_first_danes__avg_dane_im_alpha_point_1.8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the average faces from the compilation back to individual images\n",
    "average_female_oriented_ordering = [\n",
    "    'Uzbek', 'Welsh', 'West African', 'Vietnamese', 'Chinese', 'Hungarian', 'Japanese', 'Korean', 'Puerto Rican',\n",
    "    'Thai', 'African American', 'Afghan', 'Central Africa', 'Burmese', 'Cambodian', 'English', 'Ethiopian', 'Filipino'\n",
    "    'Finnish', 'French', 'German', 'Greek', 'Indian', 'Iranian', 'Irish','Israeli', 'Italian',\n",
    "    'Mexican', 'Latvian (Lithuanian)', 'Mongolain', 'Peruvian', 'Polish', 'Romanian', 'Russian', 'Samoan', 'South African',\n",
    "    'South Indian', 'Spaniard', 'Swedish', 'Swiss', 'Taiwanese'\n",
    "]\n",
    "\n",
    "average_male_oriented_ordering = [\n",
    "    'Austria', 'Afghanistan', 'Argentina', 'Burma (Myanmar)', 'Germany', 'Greece', 'India', 'Iran',\n",
    "    'Cambodia', 'England', 'Ethiopia', 'France', 'Iraq', 'Ireland', 'Israel', 'Mexico',\n",
    "    'Mongolia', 'Peru', 'Poland', 'Puerto Rico', 'Uzbekistan', 'African America', 'White America', 'China',\n",
    "    'Romania', 'Russia', 'Samoa', 'Saudi Arabia', 'Czech Republic', 'Philippines', 'Hungary', 'Italy',\n",
    "    'Serbia', 'South Africa', 'South India', 'Spain', 'Japan', 'Korea', 'Thailand', 'Brazil',\n",
    "    'Switzerland', 'Taiwan', 'Tibet', 'Ukraine', 'Vietnam', 'West Africa'\n",
    "]\n",
    "\n",
    "# row x col\n",
    "average_female_oriented_shape = (5, 9)\n",
    "average_male_oriented_shape = (6, 8)\n",
    "\n",
    "# amount of boundary in each image, (start_y, start_x, end_y, end_x)\n",
    "average_female_oriented_boundary = (0, 0, 40, 0)\n",
    "average_male_oriented_boundary = (5, 1, 15, 1)\n",
    "\n",
    "# file names\n",
    "average_female_oriented_fname = 'average_faces_around_the_world/female_oriented/averageface.jpg'\n",
    "average_male_oriented_fname = 'average_faces_around_the_world/male_oriented/average_male_faces_around_the_world.jpg'\n",
    "\n",
    "def get_image_average_faces(image_number, sex_orientation):\n",
    "    if sex_orientation == 0:\n",
    "        image_country_ordering = average_female_oriented_ordering\n",
    "        all_image_shape = average_female_oriented_shape\n",
    "        remove_boundary = average_female_oriented_boundary\n",
    "        all_image = get_file_image(average_female_oriented_fname)\n",
    "    else:\n",
    "        image_country_ordering = average_male_oriented_ordering\n",
    "        all_image_shape = average_male_oriented_shape\n",
    "        remove_boundary = average_male_oriented_boundary\n",
    "        all_image = get_file_image(average_male_oriented_fname)\n",
    "    \n",
    "    assert image_number < len(image_country_ordering)\n",
    "    image_name = image_country_ordering[image_number]\n",
    "    \n",
    "    image_size = (all_image.shape[0] // all_image_shape[0]), all_image.shape[1] // all_image_shape[1]\n",
    "    \n",
    "    row_num = image_number // all_image_shape[1]\n",
    "    col_num = image_number % all_image_shape[1]\n",
    "    \n",
    "    start_image_y, start_image_x = row_num * image_size[0] + remove_boundary[0], col_num * image_size[1] + remove_boundary[1]\n",
    "    end_image_y, end_image_x = max(0, start_image_y + image_size[0] - remove_boundary[2]), max(0, start_image_x + image_size[1] - remove_boundary[3])\n",
    "    return all_image[start_image_y:end_image_y, start_image_x:end_image_x, :], image_name\n",
    "    \n",
    "    \n",
    "# Save all image for post processing\n",
    "os.makedirs('out/average_male_oriented_face', exist_ok=True)\n",
    "for i in range(len(average_female_oriented_ordering)):\n",
    "    image, image_name = get_image_average_faces(i, 0)\n",
    "    save_image(image, 'average_female_oriented_face/' + image_name)\n",
    "\n",
    "for i in range(len(average_male_oriented_ordering)):\n",
    "    image, image_name = get_image_average_faces(i, 1)\n",
    "    save_image(image, 'average_male_oriented_face/' + image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_peru_male_oriented_img, me_tri, average_peru_male_tri = get_triangulation_from_correspondence_file('me_Peru.json', False)\n",
    "me_peru_image, me_peru_tri = morph(me_img, average_peru_male_oriented_img, me_tri, average_peru_male_tri, wrap_frac=0, dissolve_frac=0.5)\n",
    "images = [me_img, me_peru_image, average_peru_male_oriented_img]\n",
    "tris = [me_tri, me_peru_tri, average_peru_male_tri]\n",
    "\n",
    "show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "save_image(me_peru_image, \"me_peru_image_color_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_peru_male_oriented_img, me_tri, average_peru_male_tri = get_triangulation_from_correspondence_file('me_Peru.json', False)\n",
    "me_peru_image, me_peru_tri = morph(me_img, average_peru_male_oriented_img, me_tri, average_peru_male_tri, wrap_frac=0.5, dissolve_frac=0)\n",
    "images = [me_img, me_peru_image, average_peru_male_oriented_img]\n",
    "tris = [me_tri, me_peru_tri, average_peru_male_tri]\n",
    "\n",
    "show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "save_image(me_peru_image, \"me_peru_image_shape_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_peru_male_oriented_img, me_tri, average_peru_male_tri = get_triangulation_from_correspondence_file('me_Peru.json', False)\n",
    "me_peru_image, me_peru_tri = morph(me_img, average_peru_male_oriented_img, me_tri, average_peru_male_tri, wrap_frac=0.5, dissolve_frac=0.5)\n",
    "images = [me_img, me_peru_image, average_peru_male_oriented_img]\n",
    "tris = [me_tri, me_peru_tri, average_peru_male_tri]\n",
    "\n",
    "show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "save_image(me_peru_image, \"me_peru_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_ethiopia_female_oriented_img, me_tri, average_ethiopia_female_tri = get_triangulation_from_correspondence_file('me_Ethiopian.json', False)\n",
    "me_ethiopia_image, me_ethiopia_tri = morph(me_img, average_ethiopia_female_oriented_img, me_tri, average_ethiopia_female_tri, wrap_frac=0, dissolve_frac=0.5)\n",
    "images = [me_img, me_ethiopia_image, average_ethiopia_female_oriented_img]\n",
    "tris = [me_tri, me_ethiopia_tri, average_ethiopia_female_tri]\n",
    "\n",
    "show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "save_image(me_ethiopia_image, \"me_ethiopia_image_color_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_ethiopia_female_oriented_img, me_tri, average_ethiopia_female_tri = get_triangulation_from_correspondence_file('me_Ethiopian.json', False)\n",
    "me_ethiopia_image, me_ethiopia_tri = morph(me_img, average_ethiopia_female_oriented_img, me_tri, average_ethiopia_female_tri, wrap_frac=0.5, dissolve_frac=0)\n",
    "images = [me_img, me_ethiopia_image, average_ethiopia_female_oriented_img]\n",
    "tris = [me_tri, me_ethiopia_tri, average_ethiopia_female_tri]\n",
    "\n",
    "show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "save_image(me_ethiopia_image, \"me_ethiopia_image_shape_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_ethiopia_female_oriented_img, me_tri, average_ethiopia_female_tri = get_triangulation_from_correspondence_file('me_Ethiopian.json', False)\n",
    "me_ethiopia_image, me_ethiopia_tri = morph(me_img, average_ethiopia_female_oriented_img, me_tri, average_ethiopia_female_tri, wrap_frac=0.5, dissolve_frac=0.5)\n",
    "images = [me_img, me_ethiopia_image, average_ethiopia_female_oriented_img]\n",
    "tris = [me_tri, me_ethiopia_tri, average_ethiopia_female_tri]\n",
    "\n",
    "show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "save_image(me_ethiopia_image, \"me_ethiopia_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_img, average_ethiopia_female_oriented_img, me_tri, average_ethiopia_female_tri = get_triangulation_from_correspondence_file('me_Ethiopian.json', False)\n",
    "me_ethiopia_image, me_ethiopia_tri = morph(me_img, average_ethiopia_female_oriented_img, me_tri, average_ethiopia_female_tri, wrap_frac=1, dissolve_frac=0)\n",
    "images = [me_img, me_ethiopia_image, average_ethiopia_female_oriented_img]\n",
    "tris = [me_tri, me_ethiopia_tri, average_ethiopia_female_tri]\n",
    "\n",
    "show_overlay(images, tris, columns=3, is_show_all=True)\n",
    "save_image(me_ethiopia_image, \"caricatures_me_ethiopia_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eigen_face(img_list, img_pts_list, img_tris_list, mean_image=None, mean_tri=None, num_eigenfaces=None):\n",
    "    if mean_image is None or mean_tri is None:\n",
    "        mean_image = np.mean(img_list)\n",
    "    \n",
    "    face_shape = img_list[0].shape\n",
    "    face_matrix = []\n",
    "    \n",
    "    # Aligning facial landmarks to mean and flatten them\n",
    "    for img, tri in zip(img_list, img_tris_list):\n",
    "        assert img.shape == face_shape\n",
    "        aligned_img, _ = morph(img, mean_image, tri, mean_tri, wrap_frac=1, dissolve_frac=0)\n",
    "        centered_im = aligned_img - mean_image\n",
    "        face_matrix.append(centered_im.flatten())\n",
    "        \n",
    "    face_matrix = np.array(face_matrix)\n",
    "    pca = PCA().fit(face_matrix)\n",
    "    \n",
    "    eigenfaces = pca.components_\n",
    "    \n",
    "    if num_eigenfaces is not None:\n",
    "        eigenfaces = eigenfaces[:num_eigenfaces]\n",
    "    # eigenfaces = [(eigenface - eigenface.min()) / (eigenface.max() - eigenface.min()) for eigenface in eigenfaces] # Normalizing eigenfaces\n",
    "    \n",
    "    return np.array([eigenface.reshape(face_shape) for eigenface in eigenfaces])\n",
    "\n",
    "def create_caricature(target_img, mean_img, target_tri, mean_tri, eigenfaces, exaggeration_factor_list=None):\n",
    "    if exaggeration_factor_list is None:\n",
    "        exaggeration_factor_list = np.ones(eigenfaces.shape[0])\n",
    "        \n",
    "    aligned_img, _ = morph(target_img, mean_img, target_tri, mean_tri, wrap_frac=1, dissolve_frac=0)\n",
    "    \n",
    "    # Compute coefficients\n",
    "    centered_target = aligned_img.flatten() - mean_img.flatten()\n",
    "    coefficients = [np.dot(centered_target, eigenface.flatten()) for eigenface in eigenfaces]\n",
    "\n",
    "    # Exaggerate coefficients\n",
    "    exaggerated_coefficients = [coeff * exaggeration_factor for coeff, exaggeration_factor in zip(coefficients, exaggeration_factor_list)]\n",
    "    \n",
    "    \n",
    "    # Reconstruct the caricature image\n",
    "    caricature = mean_img.flatten().astype(float)\n",
    "    for coeff, eigenface in zip(exaggerated_coefficients, eigenfaces):\n",
    "        caricature += coeff * eigenface.flatten()\n",
    "    caricature = caricature.reshape(aligned_img.shape)\n",
    "    \n",
    "    # Normalize the caricature if needed\n",
    "    caricature = (caricature - caricature.min()) / (caricature.max() - caricature.min())\n",
    "\n",
    "    return caricature\n",
    "\n",
    "danes_im_list, danes_pts_list, danes_tris_list = DanesDataset().get_all_im_pts_tri()\n",
    "avg_danes_im, avg_danes_tri = average_morph(danes_im_list, danes_pts_list, danes_tris_list)\n",
    "danes_eigenfaces = get_eigen_face(danes_im_list, danes_pts_list, danes_tris_list, avg_danes_im, avg_danes_tri)\n",
    "\n",
    "display_eigenfaces = [(eigenface - eigenface.min()) / (eigenface.max() - eigenface.min()) for eigenface in danes_eigenfaces]\n",
    "\n",
    "show_images(display_eigenfaces, columns=8, figsize=(35, 21))\n",
    "        \n",
    "os.makedirs('out/danes_eigen_faces', exist_ok=True)\n",
    "for i, display_eigenface in enumerate(display_eigenfaces):\n",
    "    img_name = 'danes_eigen_face'\n",
    "    img_path = os.path.join('danes_eigen_faces', f'{img_name}_{i}')\n",
    "    save_image(display_eigenface, img_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_danes_eigenfaces = danes_eigenfaces[:1]\n",
    "exaggeration_factor_list = [1] * danes_eigenfaces.shape[0]\n",
    "reconstruct_image_im = create_caricature(avg_danes_im, avg_danes_im, avg_danes_tri, avg_danes_tri, limited_danes_eigenfaces, exaggeration_factor_list)\n",
    "skio.imshow(reconstruct_image_im)\n",
    "skio.show()\n",
    "\n",
    "os.makedirs('out/danes_caricatures/average_reconstructions', exist_ok=True)\n",
    "for i in range(1, min(len(danes_eigenfaces), 10)):\n",
    "    img_name = 'average_reconstruct_image_with_num_eigen_no_exaggeration'\n",
    "    img_path = os.path.join('danes_caricatures/average_reconstructions', f'{img_name}_{i}')\n",
    "    \n",
    "    limited_danes_eigenfaces = danes_eigenfaces[:i]\n",
    "    exaggeration_factor_list = [1] * danes_eigenfaces.shape[0]\n",
    "    reconstruct_image_im = create_caricature(avg_danes_im, avg_danes_im, avg_danes_tri, avg_danes_tri, limited_danes_eigenfaces, exaggeration_factor_list)\n",
    "    save_image(reconstruct_image_im, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_danes_eigenfaces = danes_eigenfaces[:10]\n",
    "exaggeration_factor_list = [1] * limited_danes_eigenfaces.shape[0]\n",
    "caricature_im = create_caricature(danes_im_list[0], avg_danes_im, danes_tris_list[0], avg_danes_tri, limited_danes_eigenfaces, exaggeration_factor_list)\n",
    "skio.imshow(caricature_im)\n",
    "skio.show()\n",
    "\n",
    "caricature_list = []\n",
    "os.makedirs('out/danes_caricatures/first_danes_image_reconstruction', exist_ok=True)\n",
    "for i in range(1, min(len(danes_eigenfaces), 100)):\n",
    "    img_name = 'danes_reconstruct_first_image_with_num_eigen_no_exaggeration'\n",
    "    img_path = os.path.join('danes_caricatures/first_danes_image_reconstruction', f'{img_name}_{i}')\n",
    "    \n",
    "    limited_danes_eigenfaces = danes_eigenfaces[:i]\n",
    "    exaggeration_factor_list = [1] * limited_danes_eigenfaces.shape[0]\n",
    "    reconstruct_image_im = create_caricature(danes_im_list[0], avg_danes_im, danes_tris_list[0], avg_danes_tri, limited_danes_eigenfaces, exaggeration_factor_list)\n",
    "    save_image(reconstruct_image_im, img_path)\n",
    "    caricature_list.append(reconstruct_image_im)\n",
    "    \n",
    "create_gif_from_images(caricature_list, 'danes_reconstruct_first_image_with_num_eigen_no_exaggeration.gif', duration=len(caricature_list) * 8)\n",
    "show_images(caricature_list, columns=6, figsize=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('out/danes_caricatures/first_danish_carticulation', exist_ok=True)\n",
    "\n",
    "caricature_list = []\n",
    "for i in range(1, min(len(danes_eigenfaces), 300)):\n",
    "    img_name = 'danes_reconstruct_first_image_with_random_exageration_num_eigenvalues'\n",
    "    img_path = os.path.join('danes_caricatures/first_danish_carticulation', f'{img_name}_{i}')\n",
    "    \n",
    "    limited_danes_eigenfaces = danes_eigenfaces[:]\n",
    "    exaggeration_factor_list = np.random.rand(limited_danes_eigenfaces.shape[0])\n",
    "    caricature_image_im = create_caricature(danes_im_list[0], avg_danes_im, danes_tris_list[0], avg_danes_tri, limited_danes_eigenfaces, exaggeration_factor_list)\n",
    "    save_image(caricature_image_im, img_path)\n",
    "    caricature_list.append(caricature_image_im)\n",
    "    \n",
    "create_gif_from_images(caricature_list, 'danes_reconstruct_first_image_with_random_exageration_num_eigenvalues.gif',duration=len(caricature_list) * 10)\n",
    "show_images(caricature_list, columns=6, figsize=(30, 30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
